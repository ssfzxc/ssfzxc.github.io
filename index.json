[{"categories":["linux"],"content":"关于在 ArchLinux 上使用 Rust 进行交叉编译","date":"2021-09-07","objectID":"/crosscompile/","tags":["rust","linux"],"title":"Cross Compile","uri":"/crosscompile/"},{"categories":["linux"],"content":"ArchLinux + Musl ","date":"2021-09-07","objectID":"/crosscompile/:0:0","tags":["rust","linux"],"title":"Cross Compile","uri":"/crosscompile/"},{"categories":["linux"],"content":"安装依赖 pacman -S musl kernel-headers-musl musl: musl 主体依赖 kernel-headers-musl: musl 使用的 linux-headers ","date":"2021-09-07","objectID":"/crosscompile/:1:0","tags":["rust","linux"],"title":"Cross Compile","uri":"/crosscompile/"},{"categories":["linux"],"content":"Rust rustup target add x86_64-unknown-linux-musl 参考案例: openssl mkdir /musl wget http://github.com/openssl/openssl/archive/OpenSSL_1_1_1l.tar.gz tar zxvf OpenSSL_1_1_1l.tar.gz cd OpenSSL_1_1_1l.tar.gz CC=\"musl-gcc -fPIE -pie\" ./Configure no-shared no-async --prefix=/musl --openssldir=/musl/ssl linux-x86_64 make depend make -j$(nproc) make install export PKG_CONFIG_ALLOW_CROSS=1 export OPENSSL_STATIC=true export OPENSSL_DIR=/musl cargo build --target x86_64-unknown-linux-musl TODO: 直接使用 glibc 进行静态编译 ","date":"2021-09-07","objectID":"/crosscompile/:2:0","tags":["rust","linux"],"title":"Cross Compile","uri":"/crosscompile/"},{"categories":["java"],"content":"日志跟踪, 链路跟踪","date":"2021-09-07","objectID":"/traceid/","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"日志跟踪 在生产报错查询日志恢复当时场景时, 或者在测试环境进行查询 BUG 时, 可能出现其他服务或业务日志的干扰, 这时我们系统有工具或者其他什么可用的帮助我们是筛选出我们所需要的日志. 基于通常情况, 我们会使用在定位到 Exception 处后, 使用 Grep 筛选 Thread Name, 这是一个可行有效的方案, 但是当遇到 Async 异步调用以及发送消息队列, 接下来日志的查询会是一个繁琐复杂的流程. 如何高效地, 更少地侵入业务代码的情况下, 新增一个 ID 号贯穿整个业务流程 (biz chain)? 日志新增 TraceId 接下来, 我们局部分析整个问题. 先从单应用服务开始, 引入 traceId 即一个贯穿头尾的 id, 将其在日志中打印, 实现一个 ID 贯穿业务 ","date":"2021-09-07","objectID":"/traceid/:0:0","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"什么是 TraceId？ 在业内, 日志跟踪有个高大上的名字叫做: 全链路跟踪, 其包括解决方案有 traceId 日志贯穿, 日志归集, 日志检索(ELK 全家通). 简单来说现在日志跟踪就是 使用一个 id 流水号去贯穿整个业务调用, 而 trace 用 跟踪;追溯 的意思, 所以我们用 traceId 代指 整个贯穿业务的流水号以便于区分其他如业务流水号 bizNo 等. traceId 可以使用 UUID, MongoDB ID, SnowflakeId, Random 等方式生成, 只需要保证 id 号的唯一性即可. ","date":"2021-09-07","objectID":"/traceid/:1:0","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"简单实现 我们单纯的自己使用代码去实现, 首先上文也提到了使用 threadName, 因此可以使用 ThreadLocal 对象存放 traceId, 再对所有使用 Logger 打印日志的行新增打印 traceId, 这是大家以及大佬们多使用的方法. 但是对每一行 Logger 打印日志都修改工程量太过庞大, 以及不符合我们低侵入性的想法. 如何低侵入性地修改? ","date":"2021-09-07","objectID":"/traceid/:2:0","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"什么是 MDC? 首先看看 SLF4J 的官方文档是怎么说的: 此类隐藏并充当底层日志记录系统的 MDC 实现的替代品。 如果底层日志系统提供 MDC 功能，则 SLF4J 的 MDC（即此类）将委托给底层系统的 MDC。注意，目前只有两个日志系统，即 log4j 和 logback，提供了 MDC 功能。 对于不支持 MDC 的 java.util.logging，将使用 BasicMDCAdapter。对于其他系统，即 slf4j simple 和 slf4j nop，将使用 NOPMDCAdapter。 因此，作为 SLF4J 用户，您可以在存在 log4j、logback 或 java.util.logging 的情况下利用 MDC，但不必强制将这些系统作为依赖项依赖于您的用户。 有关 MDC 的更多信息，请参阅 logback 手册中有关 MDC 的章节。 请注意，此类中的所有方法都是静态的。 还是没有说明白, MDC 全称是 Mapped Diagnostic Context，可以粗略的理解成是一个线程安全的存放诊断日志的容器。 就是一个存放当前线程上下文信息的对象. slf4j 文档说的是我们无需关注底层日志框架如何实现,slf4j 会委托给底层日志系统, 正如 slf4j 想实现的 日志门面框架 将代码和具体底层日志框架分开, 由 slf4j 做适配器桥接双方. ","date":"2021-09-07","objectID":"/traceid/:3:0","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"使用 MDC 实现 说到底 MDC 是对 ThreadLocal 的包装. 相对于我们自建 ThreadLocal 而言, 使用 MDC 我们可以直接在日志配置文件中配置输出 traceId // 将 traceId 放入 MDC MDC.put(\"traceId\", newTraceId()); // 将 traceId 放入 MDC String traceId = MDC.get(\"traceId\"); // 清除MDC 中的 traceId MDC.remove(\"traceId\"); // 清空 MDC MDC.clear(); // %X{treadId} 大跨号内的字符串保持和 MDC 的 key 相同即可 // logback 配置样例 // %date{yyyy-MM-dd HH:mm:ss.SSS} %green(%5level) --- [%15.15thread] %cyan(%-40.40logger{39}) : %magenta([%X{traceId}]) %message%n // log4j 配置样例 // %d{yyyy-MM-dd HH:mm:ss.SSS} %t %c [%X{traceId}] %m %n 使用 MDC 和少量的修改下配置文件后, 对打印 traceId 就不需要一行一行的修改 traceid 工具类样例 import org.slf4j.MDC; import java.util.Objects; /** * @author ssf on 2020-06-04 */ public final class TraceUtil { private TraceUtil() { } public static final String TRACE_ID = \"traceId\"; public static final String TRACE_FLAG_REQUEST = \"REQUEST-\"; public static final String TRACE_FLAG_TIMER = \"TIMER-\"; public static String newId(String flag) { Objects.requireNonNull(flag); String id = Ids.simpleUUID(); return flag.trim() + id; } public static String newId() { return newId(\"\"); } public static String newRequestId() { return newId(TRACE_FLAG_REQUEST); } public static void setTraceId() { MDC.put(TRACE_ID, newId()); } public static void setTraceId(String traceId) { MDC.put(TRACE_ID, traceId); } public static String getTraceId() { return MDC.get(TRACE_ID); } public static void removeTraceId() { MDC.remove(TRACE_ID); } } ","date":"2021-09-07","objectID":"/traceid/:4:0","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"Controller 新建 traceId 完成日志打印问题后新问题接踵而至, 在何处将 traceId 放入 MDC 对象中? 首先我们想到的是就是在每个 Controller 方法头和尾新增 put 和 remove 方法的调用. 但是还是不符合 低侵入性. 想想其他方式. 都是方法头和尾 - before 和 after, 可以使用 AOP 面向切面的编程. /** * aop 切面, Controller * @author ssf on 2020-06-15 */ @Aspect @Component public class RequestAndResponseDumper { //implements HandlerInterceptor { @Pointcut(\"execution(* a.b.c.*.controller.*Controller*.*(..))\") public void dump() { } @Before(\"dump()\") public void trace(JoinPoint joinPoint) { TraceUtil.setTraceId(TraceUtil.newRequestId()); } @AfterReturning(pointcut = \"dump()\", returning = \"result\") public void log(JoinPoint joinPoint, Object result) { TraceUtil.removeTraceId(); } } 还有方式: 因为是 Controller 即接口端, 也可使用 Web 容器的拦截器实现 org.springframework.web.servlet.HandlerInterceptor, preHandle 调用 put 方法, afterCompletion ( postHandle 也可, afterCompletion 更佳) 调用 remove 方法 异步 \u0026 线程 解决了单线程业务, 需要面对多线程, 而多线程问题比较麻烦, 要想低侵入性, 那么只有几点建议 ","date":"2021-09-07","objectID":"/traceid/:5:0","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"公共线程池管理 如果项目有公共的线程池管理线程, 则可以参考以下代码 /** * 线程池工具 * @author ssf on 2020-06-15 */ public final class ExecutorUtil { private ExecutorUtil() { } private static ExecutorService executor = Executors.newCachedThreadPool(new ThreadFactory() { private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; { SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"async-thread-\"; } public Thread newThread(Runnable r) { Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; } }); public static void execute(final Runnable command) { final String traceId = TraceIdUtils.getTraceId(); executor.execute(new Runnable() { @Override public void run() { TraceIdUtils.newTraceId(traceId); command.run(); TraceIdUtils.removeTraceId(); } }); } public static \u003cT\u003e Future\u003cT\u003e submit(final Callable\u003cT\u003e task) { final String traceId = TraceIdUtils.getTraceId(); return executor.submit(new Callable\u003cT\u003e() { @Override public T call() throws Exception { TraceIdUtils.newTraceId(traceId); T res = task.call(); TraceIdUtils.removeTraceId(); return res; } }); } } ","date":"2021-09-07","objectID":"/traceid/:6:0","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"SpringBoot 注解 @Async ","date":"2021-09-07","objectID":"/traceid/:7:0","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"AOP \u0026 约定 使用 AOP 以及约定相同前缀的函数名如: async…… /** * 实现异步服务的链路跟踪, traceId 的设置 * * @author ssf on 2020-06-11 */ @Aspect @Component public class AsyncServiceTracer { private final static Logger logger = LoggerFactory.getLogger(AsyncServiceTracer.class); @Pointcut(\"execution(* a.b.c.*.manager.impl.*ManagerImpl.async*(..))\") public void trace() { } @Before(value = \"trace()\") public void before(JoinPoint joinPoint) { Object[] args = joinPoint.getArgs(); if (args != null \u0026\u0026 args.length \u003e 0 \u0026\u0026 args[0] instanceof DelegateTaskDTO) { DelegateTaskDTO\u003c?\u003e delegateTask = (DelegateTaskDTO\u003c?\u003e) args[0]; TraceUtil.setTraceId(delegateTask.getDelegateId()); } else { logger.info(\"async delegate task no delegateId\"); TraceUtil.setTraceId(); } } @AfterReturning(pointcut = \"trace()\") public void after(JoinPoint joinPoint) { TraceUtil.removeTraceId(); } } ","date":"2021-09-07","objectID":"/traceid/:7:1","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"修改 SpringBoot @Async 注解配置的线程池? 未尝试, 有兴趣的可以尝试下. ","date":"2021-09-07","objectID":"/traceid/:7:2","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"new Thread 那就只能侵入代码, 修改原有代码, 或者将 new Thread() 修改为使用公共线程池. 分布式 \u0026 RPC 实现单点应用, 可以大踏步就进入分布式应用. 如何将 traceId 从 应用 A 传至应用 B 实现跨应用? 主要以 RPC 框架 Dubbo 进行说明. 主要思想就是使用其 上下文对象 存放 traceId, 将 traceId 从应用 A 传至应用 B. ","date":"2021-09-07","objectID":"/traceid/:7:3","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"Dubbo Dubbo 使用过滤器功能对 Dubbo 上下文对象 RpcContext 进行操作 import org.apache.dubbo.rpc.*; /** * @author ssf on 2020-06-09 */ public class TraceIdFilter implements Filter { @Override public Result invoke(Invoker\u003c?\u003e invoker, Invocation invocation) throws RpcException { RpcContext rpcContext = RpcContext.getContext(); // provider if (rpcContext.isProviderSide()) { String traceId = rpcContext.getAttachment(\"traceId\"); MDC.put(\"traceId\", traceId); } else if (rpcContext.isConsumerSide()) { rpcContext.setAttachment(\"traceId\", MDC.get(\"traceId\")); } Result result = invoker.invoke(invocation); if (rpcContext.isProviderSide()) { TraceUtil.removeTraceId(); } return result; } } /// 新增文件 META-INF/dubbo/com.alibaba.dubbo.rpc.Filter /// 内容: /// traceIdFilter=a.b.c.dubbo.filter.TraceIdFilter ","date":"2021-09-07","objectID":"/traceid/:8:0","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["java"],"content":"SpringCloud SpringCloud 没进行实操, 其解决思路大致为: 因为 SpringCloud 的 RPC 交互协议为 HTTP 协议, 可以将 traceId 放入 Headers 中传送至下一个应用服务 B, 应用 B 在接受到请求将 Headers 中的 traceId 取出放至 MDC [TODO]{.todo .TODO} 其他组件 将 TraceID 带入 MessageQueue 的上下文信息中, 实现 biz chain 业务链路的一体化 ","date":"2021-09-07","objectID":"/traceid/:9:0","tags":["java"],"title":"TraceID","uri":"/traceid/"},{"categories":["linux"],"content":"安装ArchLinux","date":"2021-07-14","objectID":"/arch/","tags":["运维","linux"],"title":"Hello ArchLinux","uri":"/arch/"},{"categories":["linux"],"content":"Hello Archlinux 安装 ArchLinux 时的一些笔记 ","date":"2021-07-14","objectID":"/arch/:0:0","tags":["运维","linux"],"title":"Hello ArchLinux","uri":"/arch/"},{"categories":["linux"],"content":"安装注意点 USB 启动方式一定要是 UEFI 方式 安装 key 不存在, pacman-key 命令 iwd(iwctl) wifi/wlan 链接 CLI, dhcpcd archlinuxcn 需要安装 sudo pacman -S archlinuxcn-keyring 独立显卡损坏，启动 startx 需要先禁用 ","date":"2021-07-14","objectID":"/arch/:1:0","tags":["运维","linux"],"title":"Hello ArchLinux","uri":"/arch/"},{"categories":["linux"],"content":"常用CLI jq: json formatter neofetch: 装逼神器 bat: cat 替代品 htop: top 替代品 exa: ls 替代品 iftop: net io 监控 ack/ag(the_silver_searcher)/rg(ripgrep): grep global/ctags delta: diff paru: arch AUR fd: find 替代品 ","date":"2021-07-14","objectID":"/arch/:2:0","tags":["运维","linux"],"title":"Hello ArchLinux","uri":"/arch/"},{"categories":["linux"],"content":"AUR-keyring gpg –keyserver keyserver.ubuntu.com –recv-keys 5DECDBA89270E723 gpg –keyserver keyserver.ubuntu.com –lsign-key 5DECDBA89270E723 gpg –keyserver keyserver.ubuntu.com –finger 5DECDBA89270E723\\ pacman -Syu haveged systemctl start haveged systemctl enable haveged rm -fr /etc/pacman.d/gnupg pacman-key --init pacman-key --populate archlinux pacman-key --populate archlinuxcn ","date":"2021-07-14","objectID":"/arch/:3:0","tags":["运维","linux"],"title":"Hello ArchLinux","uri":"/arch/"},{"categories":["linux"],"content":"折腾AwesomeWM awesome 使用 sudo pacman -S awesome-git, 特性更为全面 锁屏工具 i3clock 窗口合成器, 实现半透明等等功能 picom 全局应用搜索 rofi terminal kitty || alacritty ","date":"2021-07-14","objectID":"/arch/:4:0","tags":["运维","linux"],"title":"Hello ArchLinux","uri":"/arch/"},{"categories":["Jenkins"],"content":"安装 Jenkins 时的一些笔记","date":"2021-07-14","objectID":"/jenkins/","tags":["Jenkins","运维"],"title":"Hello Jenkins","uri":"/jenkins/"},{"categories":["Jenkins"],"content":"Hello Jenkins 安装 Jenkins 时的一些笔记 ","date":"2021-07-14","objectID":"/jenkins/:0:0","tags":["Jenkins","运维"],"title":"Hello Jenkins","uri":"/jenkins/"},{"categories":["Jenkins"],"content":"坑 Jenkins Job 启动后服务自动随 Job 执行完毕后关闭 Pipeline：新增 withEnv([‘JENKINS_NODE_COOKIE=background_job’]) pipeline { agent any stages { stage('startup service local') { steps { script { withEnv(['JENKINS_NODE_COOKIE=background_job']) { sh 'echo hello' } } } } } } FreeStyle: 脚本最前面新增 BUILD_ID BUILD_ID=donotKillMe echo 'hello' ","date":"2021-07-14","objectID":"/jenkins/:1:0","tags":["Jenkins","运维"],"title":"Hello Jenkins","uri":"/jenkins/"},{"categories":["杂谈"],"content":"开始写点东西","date":"2021-07-01","objectID":"/hello/","tags":["杂谈"],"title":"Hello","uri":"/hello/"},{"categories":["杂谈"],"content":"你好 ","date":"2021-07-01","objectID":"/hello/:0:0","tags":["杂谈"],"title":"Hello","uri":"/hello/"},{"categories":["杂谈"],"content":"写点东西 也不知道要干嘛，有点浮躁，决定静下心来写点什么,就从最近怎么折腾的Coroutine开始吧。 ","date":"2021-07-01","objectID":"/hello/:1:0","tags":["杂谈"],"title":"Hello","uri":"/hello/"},{"categories":["杂谈"],"content":"漫谈工作中的技术 本人从事Java开发, 作为现在企业主流后端服务开发语言技术, 所有的框架组件都在向稳定进发. JVM 虚拟机则有被 GraalVM 替代的趋势(所有底层本质上是一套东西), 分布式服务已是项目的起点, 标配组件有缓存和消息队列, 应对多服务共享数据以及削锋等操作. ","date":"2021-07-01","objectID":"/hello/:2:0","tags":["杂谈"],"title":"Hello","uri":"/hello/"},{"categories":["杂谈"],"content":"开始写点东西","date":"2021-07-01","objectID":"/ifeelcoroutine/","tags":["杂谈","开发"],"title":"个人觉得的协程","uri":"/ifeelcoroutine/"},{"categories":["杂谈"],"content":"简单说说，我觉得的协程 (Coroutine) coroutine async await Coroutine单从 IO 方面, 浅谈个人的看法和想法, 并非专业角度 此为杂谈, 内容有点乱, 后期有空再优化(开发者都懂的有空再说^ ^) ","date":"2021-07-01","objectID":"/ifeelcoroutine/:0:0","tags":["杂谈","开发"],"title":"个人觉得的协程","uri":"/ifeelcoroutine/"},{"categories":["杂谈"],"content":"Coroutine bio 同步阻塞 IO nio 同步非阻塞 IO aio 异步 IO 协程, 我最早开始知道这个概念是从 Goroutine, 然后各大语言开始出现这个 Feature (特性)(但是 Java 居然不跟进), 关键词 async 和 await 成为 coroutine 的标配. 如 python 的 gevent (底层实现 io 的上下文切换), asyncio 以及其配套 lib(aiohttp, aiomysql), javascript 的 promise 的概念拓展. ","date":"2021-07-01","objectID":"/ifeelcoroutine/:1:0","tags":["杂谈","开发"],"title":"个人觉得的协程","uri":"/ifeelcoroutine/"},{"categories":["杂谈"],"content":"Coroutine 协程 再说协程之前, 先谈下 IO, IO 作为 Web开发者来说是一个熟悉的名词, io 模型主要有 blocking io (阻塞IO)和 nonblocking io (非阻塞 IO )以及 asynchronous io (异步 IO ). 还有 IO multiplexing (io多路复用)等等. Java 的 Tomcat7 之前的版本使用的都是阻塞 IO(bio), 都实现其高并发的方式是多线程, 单位时间内一个线程对应一个IO, 会导致连接数有限, 并发量上不去(生产环境通常会有负载均衡 nginx/f5/.. +多机部署解决问题), 而 Tomcat7 之后加入了非阻塞 IO(nio), 其性能不会随线程增加而导致并发量的减少, 以及平均响应时间的恶化. 而 Java 的 nio 使用的模型是 io 多路复用. 通常使用 bio 进行读写 io ,阻塞的过程包括等待可读写状态和读写 io 数据流,而 io 多路复用将省去我们等待可读写状态的时间,通过注册消息交由系统内核去完成,如 select/poll/epoll, 而 epoll 相对于前两者来说,优化了设置队列对象直接放于内核空间(前两者在用户空间创建队列而后拷贝至内核空间), 和返回就绪的队列而不是全部队列(全部队列需要遍历查询具体哪个为就绪). ","date":"2021-07-01","objectID":"/ifeelcoroutine/:2:0","tags":["杂谈","开发"],"title":"个人觉得的协程","uri":"/ifeelcoroutine/"},{"categories":["杂谈"],"content":"Python/JavaScript’s Coroutine 相对来说, Python/Javascript 的 coroutine 从实际应用来看, 主要应用于 io 方面, 不但是 aio 还使代码逻辑没有断续感. 如下面的 python 代码,从 http 的请求到最后 responsebody 的读取,乃至于 body 转化为 json 对象都由 aiohttp 完成. # 非完整代码 import aiohttp client = aiohttp.ClientSession() async def post(): async with client.post(url, request) as response: # await response.text() json = await respnse.json() print(json) return json # asyncio.run(post()) tasks = [post for 1 in range(10)] asyncio.run(asyncio.gather(*tasks)) Coroutine/async/await 的魅力所在,就 python 而言多说几句,相对于 requests , 其在单一请求状态下就用户态 cpu 占用率的减少, 开发者对这些感知是没有,再用 gevent 的存在,让 asyncio 系列 lib 的存在意义没有那么重大 gevent 相对于 asyncio,无需关键词 async 和 await, gevent 在底层实现 io 阻塞时切换运行代码段, 简单来说,一个是自动档(gevent),一个是手动档(asyncio) 而 gevent 对社区乃至整个生态来说使更优解,少量的修改代码甚至无需修改代码只需在生产环境多安装几个环境即可体验到 aio? 的快乐, 其意义是重大的, asyncio 需要对整个系统代码进行修改和替换一定数量的第三方依赖,这对于企业来说代价是巨大的. (当然引入 gevent 也是需要代价的) 再看看 Javascript ,其 async/await 使作为 Promise 的语法糖, 其本质还是 callback. ","date":"2021-07-01","objectID":"/ifeelcoroutine/:3:0","tags":["杂谈","开发"],"title":"个人觉得的协程","uri":"/ifeelcoroutine/"},{"categories":["杂谈"],"content":"Coroutine IO 上面说到的Coroutine, 从体验上来说就可以说使aio的吧,反正个人是这么认为的. 但再细究下, 就会想到其就是nio的语法糖?, 由三方库和Interpreter实现对状态的监听以及数据的读写,完成后返回给脚本逻辑. 对于单一io处理来说, nio是否太过于麻烦,首先从业务处理逻辑来说,其断续的代码无形的增加了我们规划和编写代码的心智负担, (懒惰是人类发展的动力,引入async和await后代码逻辑开始连续了) 而我们该等待的时间并未缩短, 所以对于简单的单一的io处理使用coroutine并非优解,但是处理多io的高并发系统来说,这将是多份的快乐. corouine调度器将多个coroutine处理过程集中管理,io阻塞的将被挂起. TODO: coroutine \u0026 thread 对比 ","date":"2021-07-01","objectID":"/ifeelcoroutine/:4:0","tags":["杂谈","开发"],"title":"个人觉得的协程","uri":"/ifeelcoroutine/"}]